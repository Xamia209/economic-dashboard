import json
import os
import unicodedata
from nltk.sentiment import SentimentIntensityAnalyzer
from collections import Counter

# =====================
# LOAD DATA
# =====================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
input_path = os.path.join(BASE_DIR, "clean_data.json")

with open(input_path, "r", encoding="utf-8") as f:
    articles = json.load(f)

sia = SentimentIntensityAnalyzer()
results = []

# =====================
# SECTOR KEYWORDS
# =====================
SECTORS = {
    "banking": [
        "ngÃ¢n hÃ ng", "nhnn", "lÃ£i suáº¥t", "tÃ­n dá»¥ng", "vay",
        "lÃ£i Ä‘iá»u hÃ nh", "thanh khoáº£n", "huy Ä‘á»™ng vá»‘n",
        "ná»£ xáº¥u", "tÃ¡i cÆ¡ cáº¥u ngÃ¢n hÃ ng"
    ],

    "real_estate": [
        "báº¥t Ä‘á»™ng sáº£n", "Ä‘á»‹a á»‘c", "nhÃ  Ä‘áº¥t", "chung cÆ°",
        "dá»± Ã¡n", "thá»‹ trÆ°á»ng nhÃ ", "mua bÃ¡n nhÃ ",
        "Ä‘áº¥u giÃ¡ Ä‘áº¥t", "nhÃ  á»Ÿ xÃ£ há»™i"
    ],

    "stock": [
        "chá»©ng khoÃ¡n", "cá»• phiáº¿u", "vn-index", "vnindex",
        "hose", "hnx", "upcom", "thá»‹ trÆ°á»ng chá»©ng khoÃ¡n",
        "thá»‹ trÆ°á»ng vá»‘n", "nhÃ  Ä‘áº§u tÆ°"
    ],

    "export": [
        "xuáº¥t kháº©u", "xuáº¥t nháº­p kháº©u", "Ä‘Æ¡n hÃ ng",
        "kim ngáº¡ch", "xuáº¥t sang", "thá»‹ trÆ°á»ng nÆ°á»›c ngoÃ i"
    ],

    "macro": [
        "kinh táº¿", "tÄƒng trÆ°á»Ÿng", "láº¡m phÃ¡t", "gdp",
        "chÃ­nh sÃ¡ch", "vÄ© mÃ´", "tÃ i khÃ³a", "tiá»n tá»‡",
        "á»•n Ä‘á»‹nh kinh táº¿", "phá»¥c há»“i kinh táº¿"
    ],

    "industry": [
        "sáº£n xuáº¥t", "cÃ´ng nghiá»‡p", "nhÃ  mÃ¡y", "khu cÃ´ng nghiá»‡p",
        "cháº¿ biáº¿n", "cháº¿ táº¡o"
    ],

    "energy": [
        "nÄƒng lÆ°á»£ng", "Ä‘iá»‡n", "xÄƒng", "dáº§u",
        "giÃ¡ xÄƒng", "Ä‘iá»‡n lá»±c", "nhiÃªn liá»‡u",
        "Ä‘iá»‡n giÃ³", "Ä‘iá»‡n máº·t trá»i"
    ],

    "transport": [
        "giao thÃ´ng", "logistics", "váº­n táº£i",
        "cáº£ng biá»ƒn", "hÃ ng khÃ´ng", "Ä‘Æ°á»ng sáº¯t",
        "chuá»—i cung á»©ng"
    ],

    "retail": [
        "bÃ¡n láº»", "tiÃªu dÃ¹ng", "thá»‹ trÆ°á»ng tiÃªu dÃ¹ng",
        "siÃªu thá»‹", "doanh thu bÃ¡n láº»", "sá»©c mua"
    ],

    "technology": [
        "cÃ´ng nghá»‡", "chuyá»ƒn Ä‘á»•i sá»‘", "ai",
        "trÃ­ tuá»‡ nhÃ¢n táº¡o", "pháº§n má»m",
        "startup", "cÃ´ng nghá»‡ sá»‘"
    ],

    "agriculture": [
        "nÃ´ng nghiá»‡p", "nÃ´ng sáº£n", "lÃºa gáº¡o",
        "cÃ  phÃª", "thá»§y sáº£n", "chÄƒn nuÃ´i",
        "xuáº¥t kháº©u gáº¡o"
    ],

    "policy_law": [
        "nghá»‹ Ä‘á»‹nh", "thÃ´ng tÆ°", "luáº­t",
        "chÃ­nh phá»§", "quá»‘c há»™i",
        "cáº£i cÃ¡ch", "quy Ä‘á»‹nh má»›i"
    ]
}
# =====================
# NORMALIZE TEXT (Cá»°C Ká»² QUAN TRá»ŒNG)
# =====================
def normalize_text(text: str) -> str:
    if not text:
        return ""
    text = unicodedata.normalize("NFC", text)
    return text.lower().strip()

def detect_sector(text):
    text = normalize_text(text)

    score = {}
    for sector, keywords in SECTORS.items():
        score[sector] = sum(
            1 for kw in keywords
            if normalize_text(kw) in text
        )

    best_sector = max(score, key=score.get)

    if score[best_sector] == 0:
        return "other"

    return best_sector

# =====================
# ANALYZE ARTICLES
# =====================
for article in articles:
    title = article.get("title", "")
    description = article.get("description", "")

    text = f"{title} {description}"

    sentiment_score = sia.polarity_scores(text)
    compound = sentiment_score["compound"]

    if compound >= 0.05:
        label = "positive"
    elif compound <= -0.05:
        label = "negative"
    else:
        label = "neutral"

    article["sentiment"] = sentiment_score
    article["sentiment_label"] = label
    article["sector"] = detect_sector(text)

    results.append(article)

# =====================
# SAVE sentiment_news.json
# =====================
with open(os.path.join(BASE_DIR, "sentiment_news.json"), "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=4)

print("ðŸ”¥ Sentiment analysis done!")

# =====================
# SECTOR SUMMARY
# =====================
sector_sentiment = {}

for article in results:
    sector = article.get("sector", "other")
    sentiment = article.get("sentiment_label", "neutral")

    sector_sentiment.setdefault(sector, Counter())
    sector_sentiment[sector][sentiment] += 1

summary = {
    sector: {
        "total": sum(counter.values()),
        "positive": counter.get("positive", 0),
        "neutral": counter.get("neutral", 0),
        "negative": counter.get("negative", 0),
    }
    for sector, counter in sector_sentiment.items()
}

with open(os.path.join(BASE_DIR, "sector_sentiment_summary.json"), "w", encoding="utf-8") as f:
    json.dump(summary, f, ensure_ascii=False, indent=4)

print("âœ… Saved sector sentiment summary")
